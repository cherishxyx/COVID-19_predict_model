{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train=pd.read_excel(r'./训练集.xlsx',index_col=[0,1])\n",
    "Test=pd.read_excel(r'./测试集.xlsx',index_col=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除湖北武汉的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.drop(index=('湖北','武汉'),inplace=True)\n",
    "Test.drop(index=('湖北','武汉'),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将迁入迁出求和和比例求和，作为2个X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_train=pd.DataFrame(Train.iloc[:,0:14].sum(axis=1),columns=['迁徙指数(训练集)'])\n",
    "New_train['武汉出来的比例(训练集)']=Train.iloc[:,14:21].sum(axis=1).values\n",
    "New_train['新增感染人数']=Train.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>迁徙指数(训练集)</th>\n",
       "      <th>武汉出来的比例(训练集)</th>\n",
       "      <th>新增感染人数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>迁徙指数(训练集)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106550</td>\n",
       "      <td>0.234939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>武汉出来的比例(训练集)</td>\n",
       "      <td>0.106550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>新增感染人数</td>\n",
       "      <td>0.234939</td>\n",
       "      <td>0.931785</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              迁徙指数(训练集)  武汉出来的比例(训练集)    新增感染人数\n",
       "迁徙指数(训练集)      1.000000      0.106550  0.234939\n",
       "武汉出来的比例(训练集)   0.106550      1.000000  0.931785\n",
       "新增感染人数         0.234939      0.931785  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_train.corr()  # 相关系数分析 - 新增感染人数跟比例的相关性最大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>迁徙指数(测试集)</th>\n",
       "      <th>武汉出来的比例(测试集)</th>\n",
       "      <th>新增感染人数(测试集)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>省份</th>\n",
       "      <th>地区</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>上海</td>\n",
       "      <td>上海</td>\n",
       "      <td>166.55</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"4\" valign=\"top\">云南</td>\n",
       "      <td>临沧</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>丽江</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>保山</td>\n",
       "      <td>7.49</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>大理州</td>\n",
       "      <td>15.02</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"5\" valign=\"top\">黑龙江</td>\n",
       "      <td>绥化</td>\n",
       "      <td>15.96</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>鸡西</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>鹤岗</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>黑河</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>齐齐哈尔</td>\n",
       "      <td>11.51</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>368 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          迁徙指数(测试集)  武汉出来的比例(测试集)  新增感染人数(测试集)\n",
       "省份  地区                                        \n",
       "上海  上海       166.55        0.0334          116\n",
       "云南  临沧         4.99        0.0000            0\n",
       "    丽江         8.07        0.0000            1\n",
       "    保山         7.49        0.0000            2\n",
       "    大理州       15.02        0.0000           11\n",
       "...             ...           ...          ...\n",
       "黑龙江 绥化        15.96        0.0000           26\n",
       "    鸡西         3.12        0.0000           25\n",
       "    鹤岗         2.42        0.0000            1\n",
       "    黑河         3.65        0.0000            1\n",
       "    齐齐哈尔      11.51        0.0000           24\n",
       "\n",
       "[368 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_test=pd.DataFrame(Test.iloc[:,0:14].sum(axis=1),columns=['迁徙指数(测试集)'])\n",
    "\n",
    "New_test['武汉出来的比例(测试集)']=Test.iloc[:,14:21].sum(axis=1).values\n",
    "\n",
    "New_test['新增感染人数(测试集)']=Test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>迁徙指数(测试集)</th>\n",
       "      <th>武汉出来的比例(测试集)</th>\n",
       "      <th>新增感染人数(测试集)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>迁徙指数(测试集)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067783</td>\n",
       "      <td>0.145661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>武汉出来的比例(测试集)</td>\n",
       "      <td>0.067783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>新增感染人数(测试集)</td>\n",
       "      <td>0.145661</td>\n",
       "      <td>0.965328</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              迁徙指数(测试集)  武汉出来的比例(测试集)  新增感染人数(测试集)\n",
       "迁徙指数(测试集)      1.000000      0.067783     0.145661\n",
       "武汉出来的比例(测试集)   0.067783      1.000000     0.965328\n",
       "新增感染人数(测试集)    0.145661      0.965328     1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_test.corr() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "sc_X = StandardScaler()\n",
    "sc_Y = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_model = MLPRegressor(verbose=True,\n",
    "                        learning_rate_init=0.01,\n",
    "                         max_iter=1000,\n",
    "                         hidden_layer_sizes=(10,2),\n",
    "                         alpha=0.001,\n",
    "                         random_state=94\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X_stder = sc_X.fit_transform(New_train.iloc[:,[0,1]].values)\n",
    "sc_Y_stder = sc_Y.fit_transform(New_train.iloc[:,2].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = New_test.iloc[:,2].values.reshape(-1,1) #y_test为测试集真实值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_feat = PolynomialFeatures()  # 多项式\n",
    "poly_feat_X = poly_feat.fit_transform(sc_X_stder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.41258638\n",
      "Iteration 2, loss = 1.36341845\n",
      "Iteration 3, loss = 1.09844208\n",
      "Iteration 4, loss = 0.86125380\n",
      "Iteration 5, loss = 0.67762554\n",
      "Iteration 6, loss = 0.54553734\n",
      "Iteration 7, loss = 0.43788859\n",
      "Iteration 8, loss = 0.35231764\n",
      "Iteration 9, loss = 0.29377332\n",
      "Iteration 10, loss = 0.26070614\n",
      "Iteration 11, loss = 0.22026641\n",
      "Iteration 12, loss = 0.20410705\n",
      "Iteration 13, loss = 0.18333272\n",
      "Iteration 14, loss = 0.16635383\n",
      "Iteration 15, loss = 0.13704731\n",
      "Iteration 16, loss = 0.12833599\n",
      "Iteration 17, loss = 0.11314196\n",
      "Iteration 18, loss = 0.11204897\n",
      "Iteration 19, loss = 0.11463633\n",
      "Iteration 20, loss = 0.11353036\n",
      "Iteration 21, loss = 0.10580043\n",
      "Iteration 22, loss = 0.09643032\n",
      "Iteration 23, loss = 0.08858524\n",
      "Iteration 24, loss = 0.08734913\n",
      "Iteration 25, loss = 0.08315591\n",
      "Iteration 26, loss = 0.07960752\n",
      "Iteration 27, loss = 0.07643810\n",
      "Iteration 28, loss = 0.07659734\n",
      "Iteration 29, loss = 0.07562912\n",
      "Iteration 30, loss = 0.07302143\n",
      "Iteration 31, loss = 0.06947337\n",
      "Iteration 32, loss = 0.06839451\n",
      "Iteration 33, loss = 0.06723897\n",
      "Iteration 34, loss = 0.06632594\n",
      "Iteration 35, loss = 0.06481997\n",
      "Iteration 36, loss = 0.06346984\n",
      "Iteration 37, loss = 0.06287577\n",
      "Iteration 38, loss = 0.06269560\n",
      "Iteration 39, loss = 0.06160051\n",
      "Iteration 40, loss = 0.06112632\n",
      "Iteration 41, loss = 0.06022358\n",
      "Iteration 42, loss = 0.05966261\n",
      "Iteration 43, loss = 0.05937951\n",
      "Iteration 44, loss = 0.05906346\n",
      "Iteration 45, loss = 0.05866668\n",
      "Iteration 46, loss = 0.05815086\n",
      "Iteration 47, loss = 0.05798000\n",
      "Iteration 48, loss = 0.05755402\n",
      "Iteration 49, loss = 0.05712491\n",
      "Iteration 50, loss = 0.05694403\n",
      "Iteration 51, loss = 0.05682956\n",
      "Iteration 52, loss = 0.05629268\n",
      "Iteration 53, loss = 0.05616728\n",
      "Iteration 54, loss = 0.05604366\n",
      "Iteration 55, loss = 0.05572506\n",
      "Iteration 56, loss = 0.05524554\n",
      "Iteration 57, loss = 0.05563835\n",
      "Iteration 58, loss = 0.05494092\n",
      "Iteration 59, loss = 0.05455014\n",
      "Iteration 60, loss = 0.05465329\n",
      "Iteration 61, loss = 0.05412127\n",
      "Iteration 62, loss = 0.05384434\n",
      "Iteration 63, loss = 0.05368786\n",
      "Iteration 64, loss = 0.05351625\n",
      "Iteration 65, loss = 0.05344824\n",
      "Iteration 66, loss = 0.05293760\n",
      "Iteration 67, loss = 0.05284120\n",
      "Iteration 68, loss = 0.05274769\n",
      "Iteration 69, loss = 0.05267470\n",
      "Iteration 70, loss = 0.05224594\n",
      "Iteration 71, loss = 0.05222281\n",
      "Iteration 72, loss = 0.05191970\n",
      "Iteration 73, loss = 0.05174424\n",
      "Iteration 74, loss = 0.05150415\n",
      "Iteration 75, loss = 0.05132543\n",
      "Iteration 76, loss = 0.05124081\n",
      "Iteration 77, loss = 0.05080100\n",
      "Iteration 78, loss = 0.05093888\n",
      "Iteration 79, loss = 0.05076401\n",
      "Iteration 80, loss = 0.05044612\n",
      "Iteration 81, loss = 0.05049342\n",
      "Iteration 82, loss = 0.05017981\n",
      "Iteration 83, loss = 0.04994356\n",
      "Iteration 84, loss = 0.04978358\n",
      "Iteration 85, loss = 0.04973365\n",
      "Iteration 86, loss = 0.04949560\n",
      "Iteration 87, loss = 0.04936083\n",
      "Iteration 88, loss = 0.04951924\n",
      "Iteration 89, loss = 0.04904604\n",
      "Iteration 90, loss = 0.04916415\n",
      "Iteration 91, loss = 0.04892514\n",
      "Iteration 92, loss = 0.04873575\n",
      "Iteration 93, loss = 0.04912977\n",
      "Iteration 94, loss = 0.04860681\n",
      "Iteration 95, loss = 0.04829956\n",
      "Iteration 96, loss = 0.04807787\n",
      "Iteration 97, loss = 0.04845533\n",
      "Iteration 98, loss = 0.04803870\n",
      "Iteration 99, loss = 0.04792551\n",
      "Iteration 100, loss = 0.04782019\n",
      "Iteration 101, loss = 0.04767456\n",
      "Iteration 102, loss = 0.04794487\n",
      "Iteration 103, loss = 0.04757298\n",
      "Iteration 104, loss = 0.04731352\n",
      "Iteration 105, loss = 0.04723694\n",
      "Iteration 106, loss = 0.04714791\n",
      "Iteration 107, loss = 0.04709572\n",
      "Iteration 108, loss = 0.04698256\n",
      "Iteration 109, loss = 0.04709681\n",
      "Iteration 110, loss = 0.04685652\n",
      "Iteration 111, loss = 0.04662550\n",
      "Iteration 112, loss = 0.04661923\n",
      "Iteration 113, loss = 0.04694684\n",
      "Iteration 114, loss = 0.04672082\n",
      "Iteration 115, loss = 0.04638495\n",
      "Iteration 116, loss = 0.04644019\n",
      "Iteration 117, loss = 0.04620902\n",
      "Iteration 118, loss = 0.04653839\n",
      "Iteration 119, loss = 0.04632016\n",
      "Iteration 120, loss = 0.04640704\n",
      "Iteration 121, loss = 0.04636821\n",
      "Iteration 122, loss = 0.04599135\n",
      "Iteration 123, loss = 0.04587048\n",
      "Iteration 124, loss = 0.04597635\n",
      "Iteration 125, loss = 0.04588044\n",
      "Iteration 126, loss = 0.04564771\n",
      "Iteration 127, loss = 0.04560849\n",
      "Iteration 128, loss = 0.04579046\n",
      "Iteration 129, loss = 0.04541706\n",
      "Iteration 130, loss = 0.04628974\n",
      "Iteration 131, loss = 0.04571048\n",
      "Iteration 132, loss = 0.04561759\n",
      "Iteration 133, loss = 0.04552260\n",
      "Iteration 134, loss = 0.04526356\n",
      "Iteration 135, loss = 0.04533602\n",
      "Iteration 136, loss = 0.04499182\n",
      "Iteration 137, loss = 0.04529764\n",
      "Iteration 138, loss = 0.04504910\n",
      "Iteration 139, loss = 0.04487716\n",
      "Iteration 140, loss = 0.04517862\n",
      "Iteration 141, loss = 0.04519631\n",
      "Iteration 142, loss = 0.04491138\n",
      "Iteration 143, loss = 0.04471593\n",
      "Iteration 144, loss = 0.04472467\n",
      "Iteration 145, loss = 0.04460680\n",
      "Iteration 146, loss = 0.04454109\n",
      "Iteration 147, loss = 0.04477337\n",
      "Iteration 148, loss = 0.04444686\n",
      "Iteration 149, loss = 0.04456838\n",
      "Iteration 150, loss = 0.04437906\n",
      "Iteration 151, loss = 0.04435965\n",
      "Iteration 152, loss = 0.04428605\n",
      "Iteration 153, loss = 0.04441106\n",
      "Iteration 154, loss = 0.04431257\n",
      "Iteration 155, loss = 0.04422111\n",
      "Iteration 156, loss = 0.04448843\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(10, 2), learning_rate='constant',\n",
       "             learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=94, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.fit(poly_feat_X,sc_Y_stder.reshape(368))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9119120262411091"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model.score(poly_feat_X,sc_Y_stder) # MLP模型训练集上的R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7352483160384201"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 测试集预测\n",
    "sc_X_stder_test = sc_X.transform(New_test.iloc[:,[0,1]].values) # 测试集X归一化\n",
    "\n",
    "poly_feat_X_test = poly_feat.transform(sc_X_stder_test) # 多项式化\n",
    "\n",
    "y_test_pred = mlp_model.predict(poly_feat_X_test) \n",
    "\n",
    "sc_Y_true = sc_Y.inverse_transform(y_test_pred) #将预测结果反归一化\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,sc_Y_true)  # 测试集上的R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多项线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "lr_model = LR()\n",
    "\n",
    "sc_X_stder = sc_X.fit_transform(New_train.iloc[:,[0,1]].values)\n",
    "sc_Y_stder = sc_Y.fit_transform(New_train.iloc[:,2].values.reshape(-1,1))\n",
    "\n",
    "poly_feat = PolynomialFeatures() \n",
    "\n",
    "poly_feat_X = poly_feat.fit_transform(sc_X_stder) # 多项式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = New_test.iloc[:,2].values.reshape(-1,1) #y_test 为测试集真实值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(poly_feat_X,sc_Y_stder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8914934227244807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(poly_feat_X,sc_Y_stder) # 训练集上的R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 测试集预测\n",
    "sc_X_stder_test = sc_X.transform(New_test.iloc[:,[0,1]].values) # 归一化\n",
    "\n",
    "poly_feat_X_test = poly_feat.transform(sc_X_stder_test) # 多项化\n",
    "\n",
    "y_test_pred = lr_model.predict(poly_feat_X_test)\n",
    "\n",
    "sc_Y_true = sc_Y.inverse_transform(y_test_pred) # 将预测结果反归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.641249665958082"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test,sc_Y_true) # 测试集R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.13575146,  1.076111  , -0.00576764,  0.02525897,\n",
       "        -0.01937528]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
